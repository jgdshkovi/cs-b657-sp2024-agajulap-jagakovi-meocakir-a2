{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8092422,"sourceType":"datasetVersion","datasetId":4777804},{"sourceId":8096907,"sourceType":"datasetVersion","datasetId":4780869}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-12T05:10:38.746712Z","iopub.execute_input":"2024-04-12T05:10:38.746992Z","iopub.status.idle":"2024-04-12T05:10:40.457755Z","shell.execute_reply.started":"2024-04-12T05:10:38.746968Z","shell.execute_reply":"2024-04-12T05:10:40.456974Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\n\nimport torch\nimport torch.nn as nn\nimport math\n\n__all__ = ['effnetv2_s', 'effnetv2_m', 'effnetv2_l', 'effnetv2_xl']\n\n\ndef _make_divisible(v, divisor, min_value=None):\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    :param v:\n    :param divisor:\n    :param min_value:\n    :return:\n    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\n#if hasattr(nn, 'SiLU'): SiLU = nn.SiLU\n\n \nclass SELayer(nn.Module):\n    def __init__(self, inp, oup, reduction=4):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n                nn.Linear(oup, _make_divisible(inp // reduction, 8)),\n                SiLU(),\n                nn.Linear(_make_divisible(inp // reduction, 8), oup),\n                nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\n\ndef conv_3x3_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        SiLU()\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        SiLU()\n    )\n\n\nclass MBConv(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio, use_se):\n        super(MBConv, self).__init__()\n        assert stride in [1, 2]\n\n        hidden_dim = round(inp * expand_ratio)\n        self.identity = stride == 1 and inp == oup\n        if use_se:\n            self.conv = nn.Sequential(\n                # pw\n                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                SELayer(inp, hidden_dim),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # fused\n                nn.Conv2d(inp, hidden_dim, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n\n\n    def forward(self, x):\n        if self.identity:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n\nclass EffNetV2(nn.Module):\n    def __init__(self, cfgs, num_classes=10, width_mult=1.):\n        super(EffNetV2, self).__init__()\n        self.cfgs = cfgs\n\n        input_channel = _make_divisible(24 * width_mult, 8)\n        layers = [conv_3x3_bn(3, input_channel, 1)]  # Modified to accept 32x32 input\n        block = MBConv\n        for t, c, n, s, use_se in self.cfgs:\n            output_channel = _make_divisible(c * width_mult, 8)\n            for i in range(n):\n                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t, use_se))\n                input_channel = output_channel\n        self.features = nn.Sequential(*layers)\n        \n        # Modified to have 10 output classes\n        self.conv = conv_1x1_bn(input_channel, 1280)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(1280, num_classes)\n\n#         self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.conv(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\ndef effnetv2_s_cifar10(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-S model for CIFAR-10\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  24,  2, 1, 0],\n        [4,  48,  4, 2, 0],\n        [4,  64,  4, 2, 0],\n        [4, 128,  6, 2, 1],\n        [6, 160,  9, 1, 1],\n        [6, 256, 15, 2, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\ndef effnetv2_m_cifar10(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-M model for CIFAR-10\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  24,  3, 1, 0],\n        [4,  48,  5, 2, 0],\n        [4,  80,  5, 2, 0],\n        [4, 160,  7, 2, 1],\n        [6, 176, 14, 1, 1],\n        [6, 304, 18, 2, 1],\n        [6, 512,  5, 1, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\n# Similarly, functions for effnetv2_l_cifar10 and effnetv2_xl_cifar10 can be defined with appropriate configurations.\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:19:39.906154Z","iopub.execute_input":"2024-04-12T05:19:39.906895Z","iopub.status.idle":"2024-04-12T05:19:39.936817Z","shell.execute_reply.started":"2024-04-12T05:19:39.906863Z","shell.execute_reply":"2024-04-12T05:19:39.935873Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom torch.nn import SiLU\n\n# Define transformations for data augmentation\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100,\n                                         shuffle=False, num_workers=2)\n\n# Define the device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Define the model\nnet = effnetv2_s_cifar10()\nnet.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):  \n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 200 == 199:    # Print every 200 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 200))\n            running_loss = 0.0\n\nprint('Finished Training')\n\n# Evaluation\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n# Save the trained model and its architecture\ntorch.save(net.state_dict(), 'effnetv2_s_cifar10.pth')\n        \nprint('Accuracy of the network on the 10000 test images:', (\n    100 * correct / total))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:50:49.455649Z","iopub.execute_input":"2024-04-12T05:50:49.456054Z","iopub.status.idle":"2024-04-12T06:01:29.725438Z","shell.execute_reply.started":"2024-04-12T05:50:49.456019Z","shell.execute_reply":"2024-04-12T06:01:29.724202Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n[1,   200] loss: 1.842\n[2,   200] loss: 1.484\n[3,   200] loss: 1.283\n[4,   200] loss: 1.093\n[5,   200] loss: 0.988\n[6,   200] loss: 0.820\n[7,   200] loss: 0.827\n[8,   200] loss: 0.682\n[9,   200] loss: 0.644\n[10,   200] loss: 0.694\nFinished Training\nAccuracy of the network on the 10000 test images: 78.52\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\nimport torchvision.transforms as transforms\nimport numpy as np\n\nclass PatchShuffled_CIFAR10(Dataset):\n    def __init__(self, data_file_path = 'test_patch_16.npz', transforms = None):\n        super(PatchShuffled_CIFAR10, self).__init__()\n        with np.load(data_file_path) as k:\n           self.images = k['data']\n           self.labels = k['labels']\n        self.transform = transforms\n  \n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img, label = self.images[idx], self.labels[idx]\n        # label = torch.LongTensor([label])\n        label = torch.tensor(label, dtype=torch.long)\n        if self.transform:\n            img = self.transform(img)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:35:35.136691Z","iopub.execute_input":"2024-04-12T05:35:35.137785Z","iopub.status.idle":"2024-04-12T05:35:35.147320Z","shell.execute_reply.started":"2024-04-12T05:35:35.137742Z","shell.execute_reply":"2024-04-12T05:35:35.146195Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Evaluation\ncorrect = 0\ntotal = 0\npatch_shuffle_testset = PatchShuffled_CIFAR10(data_file_path='/kaggle/input/test-patch-16/test_patch_16.npz' , transforms=transform_test)\npatch_shuffle_testloader = DataLoader(patch_shuffle_testset, batch_size=100, shuffle=False, num_workers=2)\n\nwith torch.no_grad():\n    for data in patch_shuffle_testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy on patched: 16 npz',(\n    100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:45:15.223119Z","iopub.execute_input":"2024-04-12T05:45:15.223540Z","iopub.status.idle":"2024-04-12T05:45:18.617544Z","shell.execute_reply.started":"2024-04-12T05:45:15.223506Z","shell.execute_reply":"2024-04-12T05:45:18.616327Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy on patched: 16 npz 45.95\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation\ncorrect = 0\ntotal = 0\npatch_shuffle_testset8 = PatchShuffled_CIFAR10(data_file_path='/kaggle/input/patchtest8/test_patch_8.npz' , transforms=transform_test)\npatch_shuffle_testloader8 = DataLoader(patch_shuffle_testset8, batch_size=100, shuffle=False, num_workers=2)\n\nwith torch.no_grad():\n    for data in patch_shuffle_testloader8:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy on patched: 8 npz', (\n    100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T05:45:39.476875Z","iopub.execute_input":"2024-04-12T05:45:39.477284Z","iopub.status.idle":"2024-04-12T05:45:42.870917Z","shell.execute_reply.started":"2024-04-12T05:45:39.477245Z","shell.execute_reply":"2024-04-12T05:45:42.869752Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Accuracy on patched: 8 npz 34.3\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}